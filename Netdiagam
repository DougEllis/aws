import boto3
import ipaddress
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import time
from botocore.exceptions import ClientError

REGION = "ap-southeast-2"

# AWS Clients
session = boto3.Session(region_name=REGION)
ec2 = session.client('ec2')
logs = session.client('logs')


def classify_ip(ip):
    try:
        ip_obj = ipaddress.ip_address(ip)
        if ip_obj.is_private:
            return 'Internal'
        elif ip_obj.is_global:
            return 'External'
        else:
            return 'Unknown'
    except ValueError:
        return 'Unknown'


def get_instances():
    print("üì° Fetching EC2 instances...")
    instances = ec2.describe_instances()
    data = []
    for res in instances['Reservations']:
        for inst in res['Instances']:
            private_ip = inst.get('PrivateIpAddress')
            data.append({
                'InstanceId': inst['InstanceId'],
                'PrivateIP': private_ip,
                'PublicIP': inst.get('PublicIpAddress'),
                'NetworkInterfaces': [ni['NetworkInterfaceId'] for ni in inst.get('NetworkInterfaces', [])],
                'SecurityGroups': [sg['GroupId'] for sg in inst['SecurityGroups']],
            })
    return data


def map_ip_to_instance(instances):
    ip_map = {}
    for inst in instances:
        if inst['PrivateIP']:
            ip_map[inst['PrivateIP']] = inst['InstanceId']
        if inst['PublicIP']:
            ip_map[inst['PublicIP']] = inst['InstanceId']
    return ip_map


def get_flow_logs():
    print("üì• Retrieving VPC Flow Log configurations...")
    flow_logs = ec2.describe_flow_logs()
    return flow_logs['FlowLogs']


def get_sample_flow_events(log_group, max_streams=2, max_events=100):
    events = []

    # Check if log group exists
    try:
        logs.describe_log_groups(logGroupNamePrefix=log_group)
    except logs.exceptions.ResourceNotFoundException:
        print(f"‚ö†Ô∏è Log group not found: {log_group}")
        return events

    try:
        streams_response = logs.describe_log_streams(logGroupName=log_group)
        streams = streams_response.get('logStreams', [])
        for stream in streams[:max_streams]:
            attempts = 0
            while attempts < 3:
                try:
                    log_events = logs.get_log_events(
                        logGroupName=log_group,
                        logStreamName=stream['logStreamName'],
                        limit=max_events
                    )
                    for event in log_events['events']:
                        events.append(event['message'])
                    break
                except ClientError as e:
                    if e.response['Error']['Code'] == 'ThrottlingException':
                        attempts += 1
                        time.sleep(2 ** attempts)
                    else:
                        print(f"‚ùå Failed to fetch events from stream {stream['logStreamName']}: {e}")
                        break
    except ClientError as e:
        print(f"‚ùå Failed to get streams from {log_group}: {e}")
    return events


def parse_flow_logs(flow_logs, ip_instance_map):
    print("üîé Parsing flow log events...")
    records = []
    for flow in flow_logs:
        log_group = flow['LogGroupName']
        print(f"üì¶ Processing log group: {log_group}")
        events = get_sample_flow_events(log_group)
        if not events:
            print(f"‚ö†Ô∏è No events found or log group unavailable: {log_group}")
            continue

        for message in events:
            parts = message.split()
            if len(parts) < 14:
                continue  # Skip malformed logs

            src_ip, dst_ip = parts[3], parts[4]
            src_port, dst_port = parts[5], parts[6]

            src_type = classify_ip(src_ip)
            dst_type = classify_ip(dst_ip)

            if src_type == 'Internal' and dst_type == 'Internal':
                direction = 'Internal'
            elif src_type == 'Internal' and dst_type == 'External':
                direction = 'Outbound'
            elif src_type == 'External' and dst_type == 'Internal':
                direction = 'Inbound'
            else:
                direction = 'Unknown'

            records.append({
                'SourceIP': src_ip,
                'DestinationIP': dst_ip,
                'SourcePort': src_port,
                'DestinationPort': dst_port,
                'Direction': direction,
                'SourceInstance': ip_instance_map.get(src_ip, ''),
                'DestinationInstance': ip_instance_map.get(dst_ip, '')
            })
    return records


def export_csv(data, filename='aws_network_flows.csv'):
    df = pd.DataFrame(data)
    df.to_csv(filename, index=False)
    print(f"‚úÖ CSV export complete: {filename}")


def generate_flow_map(data):
    print("üó∫Ô∏è Generating network flow map...")
    G = nx.DiGraph()
    for record in data:
        src = f"{record['SourceIP']} ({record['SourceInstance']})" if record['SourceInstance'] else record['SourceIP']
        dst = f"{record['DestinationIP']} ({record['DestinationInstance']})" if record['DestinationInstance'] else record['DestinationIP']
        label = f"{record['SourcePort']}‚Üí{record['DestinationPort']}"
        direction = record['Direction']
        color = 'blue' if direction == 'Internal' else 'red' if direction == 'Outbound' else 'green'

        G.add_edge(src, dst, label=label, color=color)

    pos = nx.spring_layout(G, seed=42)
    edges = G.edges()
    colors = [G[u][v]['color'] for u, v in edges]
    labels = nx.get_edge_attributes(G, 'label')

    plt.figure(figsize=(14, 10))
    nx.draw(G, pos, edges=edges, edge_color=colors, with_labels=True,
            node_color='lightgray', node_size=1000, font_size=9)
    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_size=7)
    plt.title("AWS Network Flow Map", fontsize=14)
    plt.axis('off')
    plt.tight_layout()
    plt.savefig("aws_network_flow_map.png")
    plt.show()
    print("üó∫Ô∏è Visual flow map saved: aws_network_flow_map.png")


def main():
    print("üöÄ Starting AWS Network Flow Analyzer...")
    instances = get_instances()
    ip_map = map_ip_to_instance(instances)
    flows = get_flow_logs()
    flow_data = parse_flow_logs(flows, ip_map)

    if flow_data:
        export_csv(flow_data)
        generate_flow_map(flow_data)
    else:
        print("‚ö†Ô∏è No flow data was parsed. No CSV or diagram will be created.")


if __name__ == "__main__":
    main()
